#!/usr/bin/env python3
"""
üß™ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –¥–µ–ø–ª–æ—è –±–æ—Ç–∞
–í–∫–ª—é—á–∞–µ—Ç unit, integration –∏ end-to-end —Ç–µ—Å—Ç—ã
"""

import asyncio
import logging
import sys
import os
import json
import tempfile
import time
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import aiohttp
import requests
from unittest.mock import AsyncMock, MagicMock

# –î–æ–±–∞–≤–ª—è–µ–º src –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'src'))

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class TestResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞"""
    name: str
    success: bool
    duration: float
    message: str = ""
    details: Dict[str, Any] = None

class TestSuite:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –Ω–∞–±–æ—Ä–æ–≤ —Ç–µ—Å—Ç–æ–≤"""
    
    def __init__(self, name: str):
        self.name = name
        self.results: List[TestResult] = []
    
    def add_result(self, result: TestResult):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞"""
        self.results.append(result)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if result.success:
            logger.info(f"‚úÖ {result.name} - {result.duration:.2f}s")
        else:
            logger.error(f"‚ùå {result.name} - {result.message}")
    
    def get_summary(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Ç–µ—Å—Ç–∞–º"""
        total = len(self.results)
        passed = sum(1 for r in self.results if r.success)
        failed = total - passed
        
        return {
            "suite": self.name,
            "total": total,
            "passed": passed,
            "failed": failed,
            "success_rate": passed / total if total > 0 else 0,
            "duration": sum(r.duration for r in self.results)
        }

class UnitTestSuite(TestSuite):
    """Unit —Ç–µ—Å—Ç—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    
    def __init__(self):
        super().__init__("Unit Tests")
    
    async def test_imports(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–º–ø–æ—Ä—Ç –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π"""
        start_time = time.time()
        
        try:
            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏
            from core.orchestrator import Orchestrator
            from core.pdf_extractor import PDFExtractor
            from core.agents.structure_agent import StructureAgent
            from core.agents.base_agent import BaseAgent
            
            # –ë–æ—Ç –º–æ–¥—É–ª–∏
            from bot.config import config
            from bot.keyboards import get_main_keyboard
            from bot.handlers import router
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±—ä–µ–∫—Ç—ã —Å–æ–∑–¥–∞—é—Ç—Å—è
            orchestrator = Orchestrator()
            pdf_extractor = PDFExtractor()
            structure_agent = StructureAgent()
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Import modules", True, duration,
                "–í—Å–µ –º–æ–¥—É–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è —É—Å–ø–µ—à–Ω–æ"
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Import modules", False, duration,
                f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {str(e)}"
            ))
    
    async def test_pdf_extractor(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä"""
        start_time = time.time()
        
        try:
            from core.pdf_extractor import PDFExtractor
            
            extractor = PDFExtractor()
            
            # –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            assert extractor.validate_file_extension("test.pdf") == True
            assert extractor.validate_file_extension("test.txt") == False
            assert extractor.validate_file_extension("test.docx") == False
            
            # –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
            assert extractor.validate_file_size(1024) == True  # 1KB
            assert extractor.validate_file_size(15 * 1024 * 1024) == False  # 15MB
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "PDF extractor validation", True, duration,
                "PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "PDF extractor validation", False, duration,
                f"–û—à–∏–±–∫–∞ PDF —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞: {str(e)}"
            ))
    
    async def test_structure_agent(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–≥–µ–Ω—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        start_time = time.time()
        
        try:
            from core.agents.structure_agent import StructureAgent
            
            agent = StructureAgent()
            
            test_text = """
            Abstract
            This paper presents a novel approach.
            
            1. Introduction
            Machine learning has become important.
            
            2. Methodology
            We used supervised learning.
            
            3. Results
            Our experiments show improvements.
            
            4. Conclusion
            We have presented a new method.
            
            References
            [1] Smith, J. et al. (2023).
            """
            
            # –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            results = await agent.analyze(test_text, {"title": "Test Paper"})
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–∂–∏–¥–∞–µ–º—ã–µ –ø–æ–ª—è
            assert isinstance(results, dict)
            assert "found_sections" in results
            assert "structure_quality" in results
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Structure agent analysis", True, duration,
                f"–ê–≥–µ–Ω—Ç –Ω–∞—à–µ–ª {len(results.get('found_sections', []))} —Ä–∞–∑–¥–µ–ª–æ–≤"
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Structure agent analysis", False, duration,
                f"–û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞: {str(e)}"
            ))
    
    async def test_orchestrator(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä"""
        start_time = time.time()
        
        try:
            from core.orchestrator import Orchestrator
            from core.agents.structure_agent import StructureAgent
            
            orchestrator = Orchestrator()
            structure_agent = StructureAgent()
            
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–∞
            orchestrator.register_agent("StructureAgent", structure_agent)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞–≥–µ–Ω—Ç –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω
            assert "StructureAgent" in orchestrator.agents
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Orchestrator registration", True, duration,
                "–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –∞–≥–µ–Ω—Ç–æ–≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Orchestrator registration", False, duration,
                f"–û—à–∏–±–∫–∞ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞: {str(e)}"
            ))
    
    async def run_all(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ unit —Ç–µ—Å—Ç—ã"""
        logger.info(f"üî¨ –ó–∞–ø—É—Å–∫ {self.name}...")
        
        await self.test_imports()
        await self.test_pdf_extractor()
        await self.test_structure_agent()
        await self.test_orchestrator()

class IntegrationTestSuite(TestSuite):
    """Integration —Ç–µ—Å—Ç—ã –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏"""
    
    def __init__(self):
        super().__init__("Integration Tests")
    
    async def test_orchestrator_pipeline(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        start_time = time.time()
        
        try:
            from core.orchestrator import Orchestrator
            from core.agents.structure_agent import StructureAgent
            
            orchestrator = Orchestrator()
            structure_agent = StructureAgent()
            orchestrator.register_agent("StructureAgent", structure_agent)
            
            test_text = """
            Abstract
            This paper presents a comprehensive analysis of machine learning techniques.
            
            1. Introduction
            Machine learning has become increasingly important in recent years.
            
            2. Methodology
            We used a supervised learning approach with neural networks.
            
            3. Results
            Our experiments show significant improvements over baseline methods.
            
            4. Discussion
            The results demonstrate the effectiveness of our approach.
            
            5. Conclusion
            We have presented a new method that achieves state-of-the-art results.
            
            References
            [1] Smith, J. et al. (2023). Machine Learning Advances.
            """
            
            test_metadata = {
                "title": "Test Paper",
                "page_count": 10,
                "author": "Test Author"
            }
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä
            results = await orchestrator.process_paper(test_text, test_metadata)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            assert isinstance(results, dict)
            assert "processing_status" in results
            
            duration = time.time() - start_time
            status = results.get("processing_status", "unknown")
            
            self.add_result(TestResult(
                "Orchestrator pipeline", True, duration,
                f"–ü–∞–π–ø–ª–∞–π–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º: {status}",
                {"results": results}
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Orchestrator pipeline", False, duration,
                f"–û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞: {str(e)}"
            ))
    
    async def test_health_check(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç health check –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        start_time = time.time()
        
        try:
            from core.orchestrator import Orchestrator
            
            orchestrator = Orchestrator()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º health check
            health = await orchestrator.health_check()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
            assert isinstance(health, dict)
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Component health check", True, duration,
                f"Health check –≤—ã–ø–æ–ª–Ω–µ–Ω: {health}",
                {"health": health}
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Component health check", False, duration,
                f"–û—à–∏–±–∫–∞ health check: {str(e)}"
            ))
    
    async def run_all(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ integration —Ç–µ—Å—Ç—ã"""
        logger.info(f"üîó –ó–∞–ø—É—Å–∫ {self.name}...")
        
        await self.test_orchestrator_pipeline()
        await self.test_health_check()

class DeploymentTestSuite(TestSuite):
    """–¢–µ—Å—Ç—ã –¥–µ–ø–ª–æ—è –∏ —Å–µ—Ä–≤–∏—Å–æ–≤"""
    
    def __init__(self):
        super().__init__("Deployment Tests")
        self.llm_service_url = os.getenv("LLM_SERVICE_URL", "http://localhost:8000")
        self.docker_compose_file = "docker-compose.production.yml"
    
    async def test_docker_containers(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"""
        start_time = time.time()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
            result = subprocess.run(
                ["docker-compose", "-f", self.docker_compose_file, "ps"],
                capture_output=True, text=True
            )
            
            if result.returncode != 0:
                raise Exception(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è docker-compose ps: {result.stderr}")
            
            output = result.stdout
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∑–∞–ø—É—â–µ–Ω—ã
            if "Up" not in output:
                raise Exception("–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –Ω–µ –∑–∞–ø—É—â–µ–Ω—ã")
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Docker containers status", True, duration,
                "–í—Å–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∑–∞–ø—É—â–µ–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç"
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Docker containers status", False, duration,
                f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {str(e)}"
            ))
    
    async def test_llm_service_health(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM —Å–µ—Ä–≤–∏—Å–∞"""
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.llm_service_url}/health",
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status != 200:
                        raise Exception(f"LLM service health check failed: {response.status}")
                    
                    health_data = await response.json()
                    
                    duration = time.time() - start_time
                    self.add_result(TestResult(
                        "LLM service health", True, duration,
                        f"LLM —Å–µ—Ä–≤–∏—Å –¥–æ—Å—Ç—É–ø–µ–Ω: {health_data}",
                        {"health": health_data}
                    ))
                    
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "LLM service health", False, duration,
                f"LLM —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}"
            ))
    
    async def test_llm_service_models(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –≤ LLM —Å–µ—Ä–≤–∏—Å–µ"""
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{self.llm_service_url}/models",
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status != 200:
                        raise Exception(f"Models endpoint failed: {response.status}")
                    
                    models_data = await response.json()
                    
                    if not models_data.get("success"):
                        raise Exception(f"Models request failed: {models_data.get('error')}")
                    
                    models = models_data.get("models", [])
                    
                    duration = time.time() - start_time
                    self.add_result(TestResult(
                        "LLM service models", True, duration,
                        f"–î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)} - {models}",
                        {"models": models}
                    ))
                    
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "LLM service models", False, duration,
                f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {str(e)}"
            ))
    
    async def test_llm_service_review(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç endpoint —Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        start_time = time.time()
        
        try:
            test_payload = {
                "text": "This is a test paper about machine learning approaches.",
                "metadata": {"title": "Test Paper", "author": "Test Author"}
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.llm_service_url}/review",
                    json=test_payload,
                    timeout=aiohttp.ClientTimeout(total=60)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"Review endpoint failed: {response.status} - {error_text}")
                    
                    review_data = await response.json()
                    
                    if not review_data.get("success"):
                        raise Exception(f"Review failed: {review_data.get('error')}")
                    
                    results = review_data.get("results", {})
                    
                    duration = time.time() - start_time
                    self.add_result(TestResult(
                        "LLM service review", True, duration,
                        f"–†–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞ {duration:.1f}s",
                        {"results": results}
                    ))
                    
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "LLM service review", False, duration,
                f"–û—à–∏–±–∫–∞ —Ä–µ—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}"
            ))
    
    async def test_resource_usage(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        start_time = time.time()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É Docker
            result = subprocess.run(
                ["docker", "stats", "--no-stream", "--format", 
                 "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"],
                capture_output=True, text=True
            )
            
            if result.returncode != 0:
                raise Exception(f"–û—à–∏–±–∫–∞ docker stats: {result.stderr}")
            
            stats = result.stdout
            
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Resource usage", True, duration,
                "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø–æ–ª—É—á–µ–Ω–∞",
                {"stats": stats}
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Resource usage", False, duration,
                f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)}"
            ))
    
    async def run_all(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ deployment —Ç–µ—Å—Ç—ã"""
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ {self.name}...")
        
        await self.test_docker_containers()
        await self.test_llm_service_health()
        await self.test_llm_service_models()
        await self.test_llm_service_review()
        await self.test_resource_usage()

class EndToEndTestSuite(TestSuite):
    """End-to-end —Ç–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞"""
    
    def __init__(self):
        super().__init__("End-to-End Tests")
        self.llm_service_url = os.getenv("LLM_SERVICE_URL", "http://localhost:8000")
    
    async def test_full_paper_processing(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç–∞—Ç—å–∏"""
        start_time = time.time()
        
        try:
            # –ò–º–∏—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é –Ω–∞—É—á–Ω—É—é —Å—Ç–∞—Ç—å—é
            full_paper_text = """
            Title: Advanced Machine Learning Techniques for Text Analysis
            
            Abstract
            This paper presents a comprehensive analysis of advanced machine learning 
            techniques specifically designed for text analysis applications. We propose 
            a novel approach that combines neural networks with traditional NLP methods 
            to achieve superior performance in document classification and sentiment analysis.
            
            1. Introduction
            Natural language processing has become increasingly important in the era of 
            big data. Traditional approaches often struggle with the complexity and 
            nuance of human language. This paper addresses these challenges by proposing 
            a hybrid approach that leverages both modern deep learning techniques and 
            established linguistic principles.
            
            2. Related Work
            Previous work in this area has focused primarily on either deep learning 
            approaches or traditional NLP methods. Smith et al. (2022) demonstrated 
            the effectiveness of transformer models for text classification. Johnson 
            and Brown (2023) showed that traditional feature engineering can still 
            provide valuable insights.
            
            3. Methodology
            Our approach consists of three main components: (1) preprocessing pipeline 
            that normalizes text and extracts linguistic features, (2) neural network 
            architecture that processes these features, and (3) post-processing module 
            that refines the final predictions.
            
            3.1 Preprocessing Pipeline
            The preprocessing pipeline includes tokenization, stemming, and feature 
            extraction. We use a combination of TF-IDF vectors and word embeddings 
            to represent textual data.
            
            3.2 Neural Network Architecture
            Our neural network consists of multiple layers including embedding layers, 
            LSTM layers, and dense layers. The architecture is designed to capture 
            both local and global patterns in the text.
            
            4. Experiments
            We conducted extensive experiments on three benchmark datasets: Reuters-21578, 
            20 Newsgroups, and IMDB movie reviews. Our method was compared against 
            several baseline approaches including SVM, Random Forest, and BERT.
            
            4.1 Dataset Description
            Reuters-21578 contains 21,578 news articles across multiple categories. 
            20 Newsgroups consists of 20,000 newsgroup posts. IMDB dataset includes 
            50,000 movie reviews with sentiment labels.
            
            4.2 Experimental Setup
            All experiments were run on a machine with 32GB RAM and NVIDIA V100 GPU. 
            We used 80% of data for training, 10% for validation, and 10% for testing.
            
            5. Results
            Our proposed method achieved state-of-the-art performance on all three 
            datasets. On Reuters-21578, we achieved 94.2% accuracy, compared to 
            91.5% for BERT baseline. On 20 Newsgroups, our accuracy was 89.7% vs 
            87.3% for the best baseline.
            
            5.1 Ablation Study
            We conducted ablation studies to understand the contribution of each 
            component. The preprocessing pipeline contributed 2.1% improvement, 
            the neural architecture added 1.8%, and post-processing provided 0.7%.
            
            6. Discussion
            The results demonstrate that combining traditional NLP techniques with 
            modern deep learning approaches can lead to significant improvements. 
            The preprocessing pipeline is particularly important for handling noisy 
            real-world text data.
            
            6.1 Limitations
            Our approach has some limitations. The computational cost is higher than 
            simple baselines. The method requires careful hyperparameter tuning. 
            Performance on very short texts (< 10 words) is limited.
            
            7. Conclusion
            We have presented a novel hybrid approach for text analysis that combines 
            the strengths of traditional NLP and modern deep learning. Our experimental 
            results demonstrate the effectiveness of this approach across multiple 
            benchmark datasets. Future work will focus on reducing computational costs 
            and improving performance on short texts.
            
            Acknowledgments
            We thank the anonymous reviewers for their valuable feedback. This work 
            was supported by grants from NSF and NIH.
            
            References
            [1] Smith, A., Jones, B., and Wilson, C. (2022). "Transformer Models for 
                Text Classification." Proceedings of ICML, pp. 1234-1245.
                
            [2] Johnson, D. and Brown, E. (2023). "Traditional Features in Modern NLP." 
                Journal of AI Research, vol. 45, pp. 67-89.
                
            [3] Chen, F., Wang, G., and Li, H. (2021). "Deep Learning for Sentiment 
                Analysis." Neural Networks, vol. 128, pp. 45-62.
                
            [4] Davis, I. and Miller, J. (2020). "Preprocessing Techniques for Text 
                Mining." Data Mining and Knowledge Discovery, vol. 34, pp. 123-145.
            """
            
            metadata = {
                "title": "Advanced Machine Learning Techniques for Text Analysis",
                "author": "Test Author",
                "page_count": 12,
                "journal": "Test Journal",
                "year": 2024
            }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
            payload = {
                "text": full_paper_text,
                "metadata": metadata
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.llm_service_url}/review",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=120)  # 2 –º–∏–Ω—É—Ç—ã
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"E2E test failed: {response.status} - {error_text}")
                    
                    result = await response.json()
                    
                    if not result.get("success"):
                        raise Exception(f"E2E processing failed: {result.get('error')}")
                    
                    results = result.get("results", {})
                    final_review = results.get("final_review", "")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    if len(final_review) < 100:
                        logger.warning("–§–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ—Ü–µ–Ω–∑–∏—è —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è")
                    
                    duration = time.time() - start_time
                    self.add_result(TestResult(
                        "Full paper processing", True, duration,
                        f"–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {duration:.1f}s, —Ä–µ—Ü–µ–Ω–∑–∏—è: {len(final_review)} —Å–∏–º–≤–æ–ª–æ–≤",
                        {
                            "review_length": len(final_review),
                            "processing_status": results.get("processing_status"),
                            "agents_used": list(results.get("agent_results", {}).keys())
                        }
                    ))
                    
        except Exception as e:
            duration = time.time() - start_time
            self.add_result(TestResult(
                "Full paper processing", False, duration,
                f"–û—à–∏–±–∫–∞ E2E —Ç–µ—Å—Ç–∞: {str(e)}"
            ))
    
    async def run_all(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ E2E —Ç–µ—Å—Ç—ã"""
        logger.info(f"üéØ –ó–∞–ø—É—Å–∫ {self.name}...")
        
        await self.test_full_paper_processing()

class TestRunner:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    def __init__(self):
        self.suites: List[TestSuite] = []
        self.start_time = time.time()
    
    def add_suite(self, suite: TestSuite):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤"""
        self.suites.append(suite)
    
    async def run_all(self, quick_mode: bool = False):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã"""
        logger.info("üß™ –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã")
        logger.info("=" * 60)
        
        # Unit —Ç–µ—Å—Ç—ã
        unit_tests = UnitTestSuite()
        await unit_tests.run_all()
        self.add_suite(unit_tests)
        
        # Integration —Ç–µ—Å—Ç—ã
        integration_tests = IntegrationTestSuite()
        await integration_tests.run_all()
        self.add_suite(integration_tests)
        
        # Deployment —Ç–µ—Å—Ç—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ quick mode)
        if not quick_mode:
            deployment_tests = DeploymentTestSuite()
            await deployment_tests.run_all()
            self.add_suite(deployment_tests)
            
            # E2E —Ç–µ—Å—Ç—ã
            e2e_tests = EndToEndTestSuite()
            await e2e_tests.run_all()
            self.add_suite(e2e_tests)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.print_summary()
        
        return self.is_all_passed()
    
    def print_summary(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å–≤–æ–¥–∫—É –ø–æ –≤—Å–µ–º —Ç–µ—Å—Ç–∞–º"""
        total_duration = time.time() - self.start_time
        
        print("\n" + "=" * 60)
        print("üìä –°–í–û–î–ö–ê –ü–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Æ")
        print("=" * 60)
        
        total_tests = 0
        total_passed = 0
        total_failed = 0
        
        for suite in self.suites:
            summary = suite.get_summary()
            total_tests += summary["total"]
            total_passed += summary["passed"]
            total_failed += summary["failed"]
            
            status = "‚úÖ" if summary["failed"] == 0 else "‚ùå"
            print(f"{status} {summary['suite']}: {summary['passed']}/{summary['total']} "
                  f"({summary['success_rate']:.1%}) - {summary['duration']:.2f}s")
        
        print("-" * 60)
        overall_success = total_failed == 0
        status = "‚úÖ –£–°–ü–ï–®–ù–û" if overall_success else "‚ùå –ï–°–¢–¨ –û–®–ò–ë–ö–ò"
        
        print(f"{status}: {total_passed}/{total_tests} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ "
              f"({total_passed/total_tests:.1%}) –∑–∞ {total_duration:.2f}s")
        
        if total_failed > 0:
            print(f"\n‚ö†Ô∏è  –ù–µ –ø—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {total_failed}")
            print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π")
        
        print("=" * 60)
    
    def is_all_passed(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –≤—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏"""
        for suite in self.suites:
            summary = suite.get_summary()
            if summary["failed"] > 0:
                return False
        return True

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –±–æ—Ç–∞")
    parser.add_argument("--quick", action="store_true", 
                       help="–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º (—Ç–æ–ª—å–∫–æ unit –∏ integration —Ç–µ—Å—Ç—ã)")
    parser.add_argument("--unit-only", action="store_true",
                       help="–¢–æ–ª—å–∫–æ unit —Ç–µ—Å—Ç—ã")
    parser.add_argument("--deployment-only", action="store_true",
                       help="–¢–æ–ª—å–∫–æ deployment —Ç–µ—Å—Ç—ã")
    
    args = parser.parse_args()
    
    runner = TestRunner()
    
    try:
        if args.unit_only:
            unit_tests = UnitTestSuite()
            await unit_tests.run_all()
            runner.add_suite(unit_tests)
        elif args.deployment_only:
            deployment_tests = DeploymentTestSuite()
            await deployment_tests.run_all()
            runner.add_suite(deployment_tests)
        else:
            success = await runner.run_all(quick_mode=args.quick)
            
        runner.print_summary()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        if runner.is_all_passed():
            print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã! –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.")
            return 0
        else:
            print("\nüí• –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤.")
            return 1
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        return 1
    except Exception as e:
        print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code) 